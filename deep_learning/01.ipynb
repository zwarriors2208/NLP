{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f45f091-d9d1-4ab2-a58c-011be2c2edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74cebf0c-3c0b-4952-b4f9-34148a615534",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['It was nice a rainy day.', 'The things are so beautiful in his point.', 'When your focus is cleat, you won.'\n",
    "         , 'Many many happy returns of the day.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52d95b18-3e88-4f57-8a7a-10021ebd0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4501ae84-fe53-4b2c-bdd2-313f5fa670d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': 1,\n",
       " 'the': 2,\n",
       " 'many': 3,\n",
       " 'it': 4,\n",
       " 'was': 5,\n",
       " 'nice': 6,\n",
       " 'a': 7,\n",
       " 'rainy': 8,\n",
       " 'things': 9,\n",
       " 'are': 10,\n",
       " 'so': 11,\n",
       " 'beautiful': 12,\n",
       " 'in': 13,\n",
       " 'his': 14,\n",
       " 'point': 15,\n",
       " 'when': 16,\n",
       " 'your': 17,\n",
       " 'focus': 18,\n",
       " 'is': 19,\n",
       " 'cleat': 20,\n",
       " 'you': 21,\n",
       " 'won': 22,\n",
       " 'happy': 23,\n",
       " 'returns': 24,\n",
       " 'of': 25}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02a6e846-4960-4325-9213-7c87fbe0a76c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'day',\n",
       " 2: 'the',\n",
       " 3: 'many',\n",
       " 4: 'it',\n",
       " 5: 'was',\n",
       " 6: 'nice',\n",
       " 7: 'a',\n",
       " 8: 'rainy',\n",
       " 9: 'things',\n",
       " 10: 'are',\n",
       " 11: 'so',\n",
       " 12: 'beautiful',\n",
       " 13: 'in',\n",
       " 14: 'his',\n",
       " 15: 'point',\n",
       " 16: 'when',\n",
       " 17: 'your',\n",
       " 18: 'focus',\n",
       " 19: 'is',\n",
       " 20: 'cleat',\n",
       " 21: 'you',\n",
       " 22: 'won',\n",
       " 23: 'happy',\n",
       " 24: 'returns',\n",
       " 25: 'of'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30d96b11-7374-4011-848f-0255e9575971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {5: 1,\n",
       "             7: 1,\n",
       "             6: 1,\n",
       "             1: 2,\n",
       "             8: 1,\n",
       "             4: 1,\n",
       "             11: 1,\n",
       "             15: 1,\n",
       "             2: 2,\n",
       "             12: 1,\n",
       "             13: 1,\n",
       "             10: 1,\n",
       "             14: 1,\n",
       "             9: 1,\n",
       "             18: 1,\n",
       "             22: 1,\n",
       "             19: 1,\n",
       "             16: 1,\n",
       "             21: 1,\n",
       "             17: 1,\n",
       "             20: 1,\n",
       "             23: 1,\n",
       "             3: 1,\n",
       "             25: 1,\n",
       "             24: 1})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_docs # frequency corresponding to the index of number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19d81d4b-2489-4325-8500-b4bdc4622c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = tokenizer.texts_to_matrix(lines)\n",
    "mat # the words which are in the sentence will be assigned 1 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959844fb-79d9-482c-9da3-4ad292993b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf2a9e86-7441-4e96-9d0f-6f931e7f63d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 5, 6, 7, 8, 1],\n",
       " [2, 9, 10, 11, 12, 13, 14, 15],\n",
       " [16, 17, 18, 19, 20, 21, 22],\n",
       " [3, 3, 23, 24, 25, 2, 1]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = tokenizer.texts_to_sequences(lines)\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f50a7-14e2-46cd-ad4c-0feb5fa06592",
   "metadata": {},
   "source": [
    "#### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3b09ab1-4029-46a3-87aa-5dfac14498cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(seq, maxlen = 10, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8653eab-9dd6-42d4-bd0b-2df033556957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6,  7,  8,  1,  0,  0,  0,  0],\n",
       "       [ 2,  9, 10, 11, 12, 13, 14, 15,  0,  0],\n",
       "       [16, 17, 18, 19, 20, 21, 22,  0,  0,  0],\n",
       "       [ 3,  3, 23, 24, 25,  2,  1,  0,  0,  0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "965a5949-d027-450d-8aa3-c4b94fb9b3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  4,  5,  6,  7,  8,  1],\n",
       "       [ 0,  0,  2,  9, 10, 11, 12, 13, 14, 15],\n",
       "       [ 0,  0,  0, 16, 17, 18, 19, 20, 21, 22],\n",
       "       [ 0,  0,  0,  3,  3, 23, 24, 25,  2,  1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad_sequences(seq, maxlen = 10, padding = 'pre')\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1092fde6-0f8f-4954-bc94-50514efe8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data after padding on sequence is sequenctial as well as structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d7e73955-1abc-4dee-986a-434821b660ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this and matrix are both good to go but the number of features in the padding will be less and both are structured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068719dd-874d-4c16-aef8-bb7f1f3788e7",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3a209-09a6-4c3d-b736-8a7f9a4c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\DAI.STUDENTSDC\\Desktop\\NLP_CV\\dataset\\txt_sentoken-20241211T062155Z-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b256c4d-8d88-47db-bb82-230d5dbf5581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
